{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "064aa5c7",
   "metadata": {},
   "source": [
    "### 1. Convert all xlsx to csv\n",
    "Background:\n",
    "- Downloaded all datasets related to Passaic River sampling from https://sharepoint.ourpassaic.org/SitePages/Passaic%20River%20Datasets to \"xlsx_to_convert\" directory. Included: sediment, water column, biota sampling. We will need to review the datasets to determine if they arre alike enough to analyze using the same comparisons.\n",
    "- Excluded all datasets related to Newark Bay (OU3) because Newark Bay is outside our geographic scope.\n",
    "- Excluded all Bathymetry (mapping the bottom of the river) datasets because we aren't running an analysis on the physical features or water flow of the River.\n",
    "- Added all Microsoft Access datasets to a separate directory (\"access_to_convert\") because those will need a separate conversion process.\n",
    "\n",
    "\n",
    "Now attempting to add a function to open the xlsx datasets from \"xlsx_to_convert\" directory and save as csv to the \"rawdata\" directory\n",
    "-LK 4/2/2022 at 8am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1317b2ea-033b-4c27-92af-ab3cb2c1d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0fca6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_xlsx_to_csv(filename):\n",
    "    filepath = Path(f'../rawdata/xlsx_to_convert/{filename}')\n",
    "    csv_data = pd.read_excel(filepath)\n",
    "    new_filename = filepath.stem\n",
    "    return csv_data.to_csv(f'../rawdata/{new_filename}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe768ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing - it works!\n",
    "# convert_xlsx_to_csv(\"1999 Late Summer-Early Fall ESP Sampling.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d69a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013_EPA-DESA_Post_Hurricane_Sandy_Grab.xls\n",
      "2016_CPG_RM10_9_RA_SPME-Cap_Monitor.xls\n",
      "2012_LBG_Newark_Bay_SedFlume_Atterberg.xls\n"
     ]
    }
   ],
   "source": [
    "# Now I want to see if we can loop over this folder and convert all of them at once.\n",
    "xlsx_directory = '../rawdata/xlsx_to_convert'\n",
    "for filename in os.listdir(xlsx_directory):\n",
    "    if filename.endswith('.xls'):\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4517a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm re-writing the function to include the for loop inside\n",
    "def convert_xlsx_to_csv(xlsx_directory):\n",
    "    for filename in os.listdir(xlsx_directory):\n",
    "        if filename.endswith('.xlsx'):\n",
    "            filepath = Path(f'../rawdata/xlsx_to_convert/{filename}')\n",
    "            csv_data = pd.read_excel(filepath)\n",
    "            new_filename = filepath.stem\n",
    "            csv_data.to_csv(f'../rawdata/{new_filename}.csv')\n",
    "        else:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd25d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_directory = '../rawdata/xlsx_to_convert'\n",
    "# convert_xlsx_to_csv(xlsx_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3168cab",
   "metadata": {},
   "source": [
    "### 2. Narrow down the columns in our csvs to just the columns we want\n",
    "Background:\n",
    "- In class on 4/2/22 we reviewed the original datasets in excel and identified all columns we want to include in our analysis.\n",
    "- The columns are:\n",
    "['LOC_NAME',\n",
    "'SAMPLE_DATE',\n",
    "'TASK_CODE', \n",
    "'ANALYTIC_METHOD', \n",
    "'CAS_RN', \n",
    "'CHEMICAL_NAME', \n",
    "'REPORT_RESULT_VALUE', \n",
    "'REPORT_RESULT_UNIT', \n",
    "'REPORT_RESULT_LIMIT', \n",
    "'DETECT_FLAG', \n",
    "'REPORTABLE_RESULT', \n",
    "'LONGITUDE', \n",
    "'LATITUDE']\n",
    "Now we want to write a function that slices the datasets into just those columns. Potential issues are:\n",
    "- Different column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1898be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write function to open csvs\n",
    "def open_raw_csv(data_directory):\n",
    "    for filename in os.listdir(data_directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            filepath = Path(f'../rawdata/{filename}')\n",
    "            csv_data = pd.read_csv(filepath, parse_dates=True, infer_datetime_format=True)\n",
    "            our_columns = ['LOC_NAME', 'SAMPLE_DATE', 'TASK_CODE', 'ANALYTIC_METHOD', 'CAS_RN', 'CHEMICAL_NAME', 'REPORT_RESULT_VALUE', 'REPORT_RESULT_UNIT', 'REPORT_RESULT_LIMIT', 'DETECT_FLAG', 'REPORTABLE_RESULT', 'LONGITUDE', 'LATITUDE']\n",
    "            check = all(item in csv_data.columns for item in our_columns)\n",
    "            if check is True:\n",
    "                clean_data = csv_data[['LOC_NAME', 'SAMPLE_DATE', 'TASK_CODE', 'ANALYTIC_METHOD', 'CAS_RN', 'CHEMICAL_NAME', 'REPORT_RESULT_VALUE', 'REPORT_RESULT_UNIT', 'REPORT_RESULT_LIMIT', 'DETECT_FLAG', 'REPORTABLE_RESULT', 'LONGITUDE', 'LATITUDE']]\n",
    "                new_filename = filepath.stem\n",
    "                clean_data.to_csv(f'../cleandata/{new_filename}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cf2c087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d9/6r5nm8y56sbbg2kbt5s3pxhr0000gn/T/ipykernel_56994/2918624506.py:5: DtypeWarning: Columns (25,26,33,51,52,53,74,76) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv_data = pd.read_csv(filepath, parse_dates=True, infer_datetime_format=True)\n",
      "/var/folders/d9/6r5nm8y56sbbg2kbt5s3pxhr0000gn/T/ipykernel_56994/2918624506.py:5: DtypeWarning: Columns (68) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv_data = pd.read_csv(filepath, parse_dates=True, infer_datetime_format=True)\n",
      "/var/folders/d9/6r5nm8y56sbbg2kbt5s3pxhr0000gn/T/ipykernel_56994/2918624506.py:5: DtypeWarning: Columns (18,63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv_data = pd.read_csv(filepath, parse_dates=True, infer_datetime_format=True)\n",
      "/var/folders/d9/6r5nm8y56sbbg2kbt5s3pxhr0000gn/T/ipykernel_56994/2918624506.py:5: DtypeWarning: Columns (14,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv_data = pd.read_csv(filepath, parse_dates=True, infer_datetime_format=True)\n",
      "/var/folders/d9/6r5nm8y56sbbg2kbt5s3pxhr0000gn/T/ipykernel_56994/2918624506.py:5: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv_data = pd.read_csv(filepath, parse_dates=True, infer_datetime_format=True)\n",
      "/var/folders/d9/6r5nm8y56sbbg2kbt5s3pxhr0000gn/T/ipykernel_56994/2918624506.py:5: DtypeWarning: Columns (22,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv_data = pd.read_csv(filepath, parse_dates=True, infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "raw_data_dir = '../rawdata'\n",
    "for filename in os.listdir(raw_data_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            filepath = Path(f'../rawdata/{filename}')\n",
    "            csv_data = pd.read_csv(filepath, parse_dates=True, infer_datetime_format=True)\n",
    "            csv_data.columns = [col_name.upper() for col_name in csv_data.columns]\n",
    "            upper_columns = ['LOC_NAME', 'SAMPLE_DATE', 'TASK_CODE', 'ANALYTIC_METHOD', 'CAS_RN', 'CHEMICAL_NAME', 'REPORT_RESULT_VALUE', 'REPORT_RESULT_UNIT', 'REPORT_RESULT_LIMIT', 'DETECT_FLAG', 'REPORTABLE_RESULT', 'LONGITUDE', 'LATITUDE']\n",
    "            check = all(item in csv_data.columns for item in upper_columns)\n",
    "            if check is True:\n",
    "                clean_data = csv_data[upper_columns]\n",
    "                new_filename = filepath.stem\n",
    "                clean_data.to_csv(f'../cleandata/{new_filename}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fc34c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 Late Summer-Early Fall ESP Sampling.csv\n",
      "2015 ERT RM10.9 Suface Sediment Sampling.csv\n",
      "1990 Surficial Sediment Investigation.csv\n",
      "2010 CPG LPR-NB PWCM Field Measurements.csv\n",
      "2012 CPG Tissue Survey Above Dundee Dam.csv\n",
      "2018-2019_Diamond-Alkali_OU2_EPA-PDI-Split-samples.csv\n",
      "2012 CPG Benthic Sediment Above Dundee Dam.csv\n",
      "1995-96 Passaic Study RI_FS Sed Mobility EPA.csv\n",
      "2018-2019_OU2_PDI_Treatability Study_20210924.csv\n",
      "1981-2014_RPI(Bopp)SED-SUS_Matter.csv\n",
      "1999-2000 Minish Park Monitoring Program.csv\n",
      "2019_OU2_PDI_Porewater_Passive_Sampler_20210924.csv\n",
      "2001 Supplemental ESP Biota Sampling.csv\n",
      "1995 USACE Minish Park Investigation.csv\n",
      "2013_EPA-DESA_Post_Hurricane_Sandy_Grab.csv\n",
      "2010 CPG LPR-NB PWCM Sample Dataset.csv\n",
      "1997 Outfall Sampling Program.csv\n",
      "2000 Spring ESP Sampling Program.csv\n",
      "1991-1993 Core Sediment Investigations.csv\n",
      "1995 Sediment Grab Sampling Program.csv\n",
      "2012 OU3 NBSA SedFlume Atterberg Limits.csv\n",
      "2016_CPG_RM10_9_RA_SPME-Cap_Monitor.csv\n",
      "2012_LBG_Newark_Bay_SedFlume_Atterberg.csv\n",
      "1999 Sediment Sampling Program.csv\n",
      "2004 EarthTech SED Coring Pilot Project.csv\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(raw_data_dir):\n",
    "    if filename.endswith('.csv'):\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02f3cd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d9/6r5nm8y56sbbg2kbt5s3pxhr0000gn/T/ipykernel_56994/1946028009.py:2: DtypeWarning: Columns (14,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv_data = pd.read_csv(filepath, parse_dates=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC_NAME</th>\n",
       "      <th>SAMPLE_DATE</th>\n",
       "      <th>TASK_CODE</th>\n",
       "      <th>ANALYTIC_METHOD</th>\n",
       "      <th>CAS_RN</th>\n",
       "      <th>CHEMICAL_NAME</th>\n",
       "      <th>REPORT_RESULT_VALUE</th>\n",
       "      <th>REPORT_RESULT_UNIT</th>\n",
       "      <th>REPORT_RESULT_LIMIT</th>\n",
       "      <th>DETECT_FLAG</th>\n",
       "      <th>REPORTABLE_RESULT</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RM 2.9</td>\n",
       "      <td>2018-11-18 11:40:00</td>\n",
       "      <td>2018-2019 OU2 PDI Treatability Study</td>\n",
       "      <td>E1668A</td>\n",
       "      <td>WHOTOTTEQ(H)1</td>\n",
       "      <td>Total WHO PCB/Dioxin TEQ(Human/Mammal)(ND=1)</td>\n",
       "      <td>304.0</td>\n",
       "      <td>pg/g</td>\n",
       "      <td>6.340</td>\n",
       "      <td>Y</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-74.12643</td>\n",
       "      <td>40.742445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RM 2.9</td>\n",
       "      <td>2018-11-18 11:40:00</td>\n",
       "      <td>2018-2019 OU2 PDI Treatability Study</td>\n",
       "      <td>E1668A</td>\n",
       "      <td>WHOTOTTEQ(H)0</td>\n",
       "      <td>Total WHO PCB/Dioxin TEQ(Human/Mammal)(ND=0)</td>\n",
       "      <td>304.0</td>\n",
       "      <td>pg/g</td>\n",
       "      <td>6.340</td>\n",
       "      <td>Y</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-74.12643</td>\n",
       "      <td>40.742445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RM 2.9</td>\n",
       "      <td>2018-11-18 11:40:00</td>\n",
       "      <td>2018-2019 OU2 PDI Treatability Study</td>\n",
       "      <td>E1668A</td>\n",
       "      <td>WHOTOTTEQ(H)5</td>\n",
       "      <td>Total WHO PCB/Dioxin TEQ(Human/Mammal)(ND=0.5)</td>\n",
       "      <td>304.0</td>\n",
       "      <td>pg/g</td>\n",
       "      <td>6.340</td>\n",
       "      <td>Y</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-74.12643</td>\n",
       "      <td>40.742445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RM 2.9</td>\n",
       "      <td>2018-11-18 11:40:00</td>\n",
       "      <td>2018-2019 OU2 PDI Treatability Study</td>\n",
       "      <td>E1668A</td>\n",
       "      <td>WHOTOTTEQ(F)5</td>\n",
       "      <td>Total WHO PCB/Dioxin TEQ(Fish)(ND=0.5)</td>\n",
       "      <td>279.0</td>\n",
       "      <td>pg/g</td>\n",
       "      <td>0.596</td>\n",
       "      <td>Y</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-74.12643</td>\n",
       "      <td>40.742445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RM 2.9</td>\n",
       "      <td>2018-11-18 11:40:00</td>\n",
       "      <td>2018-2019 OU2 PDI Treatability Study</td>\n",
       "      <td>E1668A</td>\n",
       "      <td>WHOTOTTEQ(F)1</td>\n",
       "      <td>Total WHO PCB/Dioxin TEQ(Fish)(ND=1)</td>\n",
       "      <td>280.0</td>\n",
       "      <td>pg/g</td>\n",
       "      <td>0.596</td>\n",
       "      <td>Y</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-74.12643</td>\n",
       "      <td>40.742445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LOC_NAME          SAMPLE_DATE                             TASK_CODE  \\\n",
       "0   RM 2.9  2018-11-18 11:40:00  2018-2019 OU2 PDI Treatability Study   \n",
       "1   RM 2.9  2018-11-18 11:40:00  2018-2019 OU2 PDI Treatability Study   \n",
       "2   RM 2.9  2018-11-18 11:40:00  2018-2019 OU2 PDI Treatability Study   \n",
       "3   RM 2.9  2018-11-18 11:40:00  2018-2019 OU2 PDI Treatability Study   \n",
       "4   RM 2.9  2018-11-18 11:40:00  2018-2019 OU2 PDI Treatability Study   \n",
       "\n",
       "  ANALYTIC_METHOD         CAS_RN  \\\n",
       "0          E1668A  WHOTOTTEQ(H)1   \n",
       "1          E1668A  WHOTOTTEQ(H)0   \n",
       "2          E1668A  WHOTOTTEQ(H)5   \n",
       "3          E1668A  WHOTOTTEQ(F)5   \n",
       "4          E1668A  WHOTOTTEQ(F)1   \n",
       "\n",
       "                                    CHEMICAL_NAME  REPORT_RESULT_VALUE  \\\n",
       "0    Total WHO PCB/Dioxin TEQ(Human/Mammal)(ND=1)                304.0   \n",
       "1    Total WHO PCB/Dioxin TEQ(Human/Mammal)(ND=0)                304.0   \n",
       "2  Total WHO PCB/Dioxin TEQ(Human/Mammal)(ND=0.5)                304.0   \n",
       "3          Total WHO PCB/Dioxin TEQ(Fish)(ND=0.5)                279.0   \n",
       "4            Total WHO PCB/Dioxin TEQ(Fish)(ND=1)                280.0   \n",
       "\n",
       "  REPORT_RESULT_UNIT  REPORT_RESULT_LIMIT DETECT_FLAG REPORTABLE_RESULT  \\\n",
       "0               pg/g                6.340           Y               Yes   \n",
       "1               pg/g                6.340           Y               Yes   \n",
       "2               pg/g                6.340           Y               Yes   \n",
       "3               pg/g                0.596           Y               Yes   \n",
       "4               pg/g                0.596           Y               Yes   \n",
       "\n",
       "   LONGITUDE   LATITUDE  \n",
       "0  -74.12643  40.742445  \n",
       "1  -74.12643  40.742445  \n",
       "2  -74.12643  40.742445  \n",
       "3  -74.12643  40.742445  \n",
       "4  -74.12643  40.742445  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '/Users/laurenkrohn/Documents/GitHub-Local/project_1/environmental-contamination/data/rawdata/2018-2019_OU2_PDI_Treatability Study_20210924.csv'\n",
    "csv_data = pd.read_csv(filepath, parse_dates=True, infer_datetime_format=True)\n",
    "clean_data = csv_data[['LOC_NAME', 'SAMPLE_DATE', 'TASK_CODE', 'ANALYTIC_METHOD', 'CAS_RN', 'CHEMICAL_NAME', 'REPORT_RESULT_VALUE', 'REPORT_RESULT_UNIT', 'REPORT_RESULT_LIMIT', 'DETECT_FLAG', 'REPORTABLE_RESULT', 'LONGITUDE', 'LATITUDE']]\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08717ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c8bdce3",
   "metadata": {},
   "source": [
    "def open_one_csv(filename):\n",
    "    for filename in os.listdir(data_directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            filepath = Path(f'../rawdata/{filename}')\n",
    "            csv_data = pd.read_csv(filepath, parse_dates=True, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e11a41b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
